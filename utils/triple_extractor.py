# utils/triple_extractor.py - AI Claim Extraction from Natural Language
"""
Module nÃ y sá»­ dá»¥ng OpenAI Ä‘á»ƒ tá»± Ä‘á»™ng extract Claims tá»« text tá»± nhiÃªn.
User nháº­p mÃ´ táº£ bÃ¬nh thÆ°á»ng, AI sáº½ chuyá»ƒn thÃ nh Claim objects vá»›i:
- content_summary: MÃ´ táº£ chi tiáº¿t cho RAG
- entities: CÃ¡c entities Ä‘Æ°á»£c nháº¯c Ä‘áº¿n
- topic: PhÃ¢n loáº¡i chá»§ Ä‘á»

Output theo schema má»›i: Claim, Entity (vá»›i canonical_id)
"""

import json
from typing import List, Dict, Tuple, Optional
from openai import OpenAI

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import get_openai_api_key, LLM_MODEL, CLAIM_TOPICS, CONFIDENCE_SCORES
from models.schema import Claim, Entity, Evidence, ClaimStatus, create_claim_from_input
from utils.entity_linker import link_or_create_entity, get_entity_linker


# ============================================================================
# CATEGORY MAPPING
# ============================================================================

# Map tá»« category UI vá» topic trong schema
CATEGORY_TO_TOPIC = {
    "experience": "work",
    "skill": "skill",
    "project": "project",
    "certificate": "certificate",
    "education": "education",
    "achievement": "achievement",
    "connection": "other",
    "bio": "other"
}

# Category display names (Vietnamese)
CATEGORY_DISPLAY = {
    "experience": "ðŸ’¼ Kinh nghiá»‡m lÃ m viá»‡c",
    "skill": "ðŸ› ï¸ Ká»¹ nÄƒng",
    "project": "ðŸ“ Dá»± Ã¡n",
    "certificate": "ðŸ“œ Chá»©ng chá»‰ & KhÃ³a há»c",
    "education": "ðŸŽ“ Há»c váº¥n",
    "achievement": "ðŸ† ThÃ nh tÃ­ch & Giáº£i thÆ°á»Ÿng",
    "connection": "ðŸ¤ Káº¿t ná»‘i & Endorsement"
}

CATEGORY_PLACEHOLDERS = {
    "experience": "VÃ­ dá»¥: TÃ´i lÃ m Senior Developer táº¡i TechCorp tá»« 2022, phá»¥ trÃ¡ch backend vá»›i Python vÃ  FastAPI...",
    "skill": "VÃ­ dá»¥: ThÃ nh tháº¡o Python, React, Docker. CÃ³ kinh nghiá»‡m vá»›i AWS vÃ  Kubernetes...",
    "project": "VÃ­ dá»¥: XÃ¢y dá»±ng há»‡ thá»‘ng RAG cho chatbot há»— trá»£ khÃ¡ch hÃ ng, sá»­ dá»¥ng LangChain vÃ  OpenAI...",
    "certificate": "VÃ­ dá»¥: HoÃ n thÃ nh khÃ³a Machine Learning cá»§a Coursera, Ä‘áº¡t chá»©ng chá»‰ AWS Solutions Architect...",
    "education": "VÃ­ dá»¥: Tá»‘t nghiá»‡p Äáº¡i há»c BÃ¡ch Khoa chuyÃªn ngÃ nh Khoa há»c MÃ¡y tÃ­nh nÄƒm 2020...",
    "achievement": "VÃ­ dá»¥: Äáº¡t giáº£i nháº¥t Hackathon AI 2024, Ä‘Æ°á»£c vinh danh Top 10 Developer of the Year...",
    "connection": "VÃ­ dá»¥: ÄÆ°á»£c Alice (Senior Manager táº¡i Google) endorse vá» ká»¹ nÄƒng Machine Learning..."
}


# ============================================================================
# CLAIM EXTRACTION PROMPT
# ============================================================================

def build_claim_extraction_prompt(user_id: str, category: str, description: str, evidence: str) -> str:
    """
    XÃ¢y dá»±ng prompt Ä‘á»ƒ AI extract Claim vá»›i entities.
    
    Args:
        user_id: ID cá»§a user Ä‘ang nháº­p
        category: Loáº¡i thÃ´ng tin (experience, skill, project, etc.)
        description: MÃ´ táº£ tá»± nhiÃªn tá»« user
        evidence: Link báº±ng chá»©ng (náº¿u cÃ³)
        
    Returns:
        Prompt string
    """
    topic = CLAIM_TOPICS.get(CATEGORY_TO_TOPIC.get(category, "other"), "Other")
    
    return f"""Báº¡n lÃ  AI chuyÃªn phÃ¢n tÃ­ch thÃ´ng tin cÃ¡ nhÃ¢n vÃ  trÃ­ch xuáº¥t thÃ nh Claims cho Knowledge Graph.

Nhiá»‡m vá»¥: PhÃ¢n tÃ­ch mÃ´ táº£ sau vÃ  táº¡o cÃ¡c Claim objects vá»›i entities liÃªn quan.

User ID: {user_id}
Loáº¡i thÃ´ng tin: {category}
Topic chuáº©n: {topic}
MÃ´ táº£: "{description}"
Báº±ng chá»©ng: {evidence if evidence else "KhÃ´ng cÃ³"}

Quy táº¯c trÃ­ch xuáº¥t:
1. Má»—i Claim lÃ  má»™t kháº³ng Ä‘á»‹nh Cá»¤ THá»‚ vÃ  Äá»˜C Láº¬P
2. content_summary pháº£i chi tiáº¿t Ä‘á»§ Ä‘á»ƒ AI cÃ³ thá»ƒ tráº£ lá»i cÃ¢u há»i vá» user
3. entities lÃ  danh sÃ¡ch cÃ¡c thá»±c thá»ƒ (skills, cÃ´ng ty, trÆ°á»ng há»c, chá»©ng chá»‰...)
4. Má»—i entity cÃ³ type: Skill, Organization, Project, Certificate, Education, Achievement

Tráº£ vá» JSON vá»›i format:
```json
{{
  "claims": [
    {{
      "content_summary": "User {user_id} cÃ³ 3 nÄƒm kinh nghiá»‡m lÃ m viá»‡c vá»›i Python táº¡i TechCorp...",
      "entities": [
        {{"name": "Python", "type": "Skill"}},
        {{"name": "TechCorp", "type": "Organization"}}
      ]
    }}
  ]
}}
```

Quan trá»ng:
- content_summary pháº£i Báº®T Äáº¦U báº±ng "User {user_id}" Ä‘á»ƒ dá»… search
- Náº¿u cÃ³ nhiá»u thÃ´ng tin khÃ¡c nhau, táº¡o nhiá»u claims
- Entities pháº£i cá»¥ thá»ƒ (Python thay vÃ¬ "programming language")

Chá»‰ tráº£ vá» JSON, khÃ´ng giáº£i thÃ­ch thÃªm."""


# ============================================================================
# MAIN EXTRACTION FUNCTION
# ============================================================================

def extract_claims(
    user_id: str, 
    category: str, 
    description: str, 
    evidence: str = "",
    access_level: str = "public"
) -> Tuple[List[Claim], List[Entity], Optional[Evidence]]:
    """
    Sá»­ dá»¥ng AI Ä‘á»ƒ extract Claims, Entities tá»« mÃ´ táº£ tá»± nhiÃªn.
    
    Args:
        user_id: ID cá»§a user
        category: Loáº¡i thÃ´ng tin
        description: MÃ´ táº£ tá»« user
        evidence: Link báº±ng chá»©ng
        access_level: Má»©c Ä‘á»™ truy cáº­p
        
    Returns:
        Tuple: (List[Claim], List[Entity], Evidence or None)
    """
    if not description.strip():
        return [], [], None
    
    client = OpenAI(api_key=get_openai_api_key())
    prompt = build_claim_extraction_prompt(user_id, category, description, evidence)
    
    try:
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=1000
        )
        
        content = response.choices[0].message.content.strip()
        
        # Parse JSON tá»« response
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()
        
        data = json.loads(content)
        claims_data = data.get("claims", [])
        
        # Build Claim vÃ  Entity objects
        claims = []
        all_entities = []
        entity_linker = get_entity_linker()
        
        # Táº¡o Evidence náº¿u cÃ³
        evidence_obj = None
        if evidence.strip():
            evidence_obj = Evidence(url=evidence)
        
        topic = CLAIM_TOPICS.get(CATEGORY_TO_TOPIC.get(category, "other"), "Other")
        
        for claim_data in claims_data:
            content_summary = claim_data.get("content_summary", "")
            entities_data = claim_data.get("entities", [])
            
            # Create Entity objects vá»›i canonical_id
            entity_ids = []
            for ent in entities_data:
                ent_name = ent.get("name", "")
                ent_type = ent.get("type", "Skill")
                
                # Link vá» canonical_id
                canonical_id = link_or_create_entity(ent_name, ent_type)
                
                entity = Entity(
                    name=ent_name,
                    canonical_id=canonical_id,
                    entity_type=ent_type
                )
                all_entities.append(entity)
                entity_ids.append(canonical_id)
            
            # Create Claim
            claim = Claim(
                user_id=user_id,
                topic=topic,
                content_summary=content_summary,
                access_level=access_level,
                status=ClaimStatus.SELF_DECLARED.value,
                confidence_score=CONFIDENCE_SCORES['base_self_declared'],
                entity_ids=entity_ids
            )
            
            # Add evidence if exists
            if evidence_obj:
                claim.evidence_ids.append(evidence_obj.evidence_id)
                claim.calculate_confidence_score(has_evidence=True)
            
            claims.append(claim)
        
        return claims, all_entities, evidence_obj
        
    except json.JSONDecodeError:
        # Fallback: táº¡o claim Ä‘Æ¡n giáº£n
        topic = CLAIM_TOPICS.get(CATEGORY_TO_TOPIC.get(category, "other"), "Other")
        claim = Claim(
            user_id=user_id,
            topic=topic,
            content_summary=f"User {user_id}: {description[:200]}",
            access_level=access_level,
            status=ClaimStatus.SELF_DECLARED.value,
            confidence_score=CONFIDENCE_SCORES['base_self_declared']
        )
        
        evidence_obj = None
        if evidence.strip():
            evidence_obj = Evidence(url=evidence)
            claim.evidence_ids.append(evidence_obj.evidence_id)
            claim.calculate_confidence_score(has_evidence=True)
        
        return [claim], [], evidence_obj
        
    except Exception as e:
        print(f"Error extracting claims: {str(e)}")
        return [], [], None


# ============================================================================
# BACKWARD COMPATIBILITY - Legacy Triple Format
# ============================================================================

def extract_triples(user_id: str, category: str, description: str, 
                    evidence: str = "") -> list:
    """
    LEGACY: Sá»­ dá»¥ng AI Ä‘á»ƒ extract triples tá»« mÃ´ táº£ tá»± nhiÃªn.
    Giá»¯ láº¡i cho backward compatibility vá»›i code cÅ©.
    
    Returns:
        List cÃ¡c triples dáº¡ng dict vá»›i keys: Source, Relation, Target, Evidence
    """
    claims, entities, evidence_obj = extract_claims(user_id, category, description, evidence)
    
    # Convert claims sang format triples cÅ©
    triples = []
    for claim in claims:
        for entity_id in claim.entity_ids:
            triples.append({
                "Source": claim.user_id,
                "Relation": f"HAS_{claim.topic.upper().replace(' ', '_')}",
                "Target": entity_id,
                "Evidence": evidence if evidence else "",
                "Access_Level": claim.access_level,
                "Status": claim.status,
                "Confidence_Score": claim.confidence_score,
                "Content_Summary": claim.content_summary
            })
    
    # Náº¿u khÃ´ng cÃ³ entities, táº¡o triple vá»›i content lÃ m target
    if not triples and claims:
        for claim in claims:
            triples.append({
                "Source": claim.user_id,
                "Relation": f"HAS_{claim.topic.upper().replace(' ', '_')}",
                "Target": claim.content_summary[:100],
                "Evidence": evidence if evidence else "",
                "Access_Level": claim.access_level,
                "Status": claim.status,
                "Confidence_Score": claim.confidence_score,
                "Content_Summary": claim.content_summary
            })
    
    return triples


# ============================================================================
# PREVIEW FUNCTIONS
# ============================================================================

def preview_claims(claims: List[Claim], entities: List[Entity]) -> str:
    """
    Táº¡o preview text cho cÃ¡c Claims Ä‘Ã£ extract.
    
    Args:
        claims: List cÃ¡c Claims
        entities: List cÃ¡c Entities
        
    Returns:
        Formatted string Ä‘á»ƒ hiá»ƒn thá»‹
    """
    if not claims:
        return "KhÃ´ng cÃ³ thÃ´ng tin Ä‘á»ƒ trÃ­ch xuáº¥t."
    
    lines = ["**ðŸ“‹ Claims sáº½ Ä‘Æ°á»£c lÆ°u:**", ""]
    
    for i, claim in enumerate(claims, 1):
        confidence_emoji = "ðŸŸ¢" if claim.confidence_score >= 0.8 else "ðŸŸ¡" if claim.confidence_score >= 0.5 else "ðŸ”´"
        lines.append(f"**{i}. {claim.topic}** {confidence_emoji} ({claim.confidence_score:.1%} tin cáº­y)")
        lines.append(f"   ðŸ“ {claim.content_summary[:150]}...")
        lines.append("")
    
    if entities:
        lines.append("**ðŸ·ï¸ Entities Ä‘Æ°á»£c phÃ¡t hiá»‡n:**")
        unique_entities = {e.canonical_id: e for e in entities}
        for ent in unique_entities.values():
            lines.append(f"   â€¢ {ent.name} ({ent.entity_type})")
    
    return "\n".join(lines)


def preview_triples(triples: list) -> str:
    """
    LEGACY: Táº¡o preview text cho cÃ¡c triples Ä‘Ã£ extract.
    
    Args:
        triples: List cÃ¡c triples
        
    Returns:
        Formatted string Ä‘á»ƒ hiá»ƒn thá»‹
    """
    if not triples:
        return "KhÃ´ng cÃ³ thÃ´ng tin Ä‘á»ƒ trÃ­ch xuáº¥t."
    
    lines = ["**ThÃ´ng tin sáº½ Ä‘Æ°á»£c lÆ°u:**", ""]
    for i, t in enumerate(triples, 1):
        confidence = t.get('Confidence_Score', 0.3)
        confidence_emoji = "ðŸŸ¢" if confidence >= 0.8 else "ðŸŸ¡" if confidence >= 0.5 else "ðŸ”´"
        lines.append(f"{i}. `{t['Source']}` â†’ **{t['Relation']}** â†’ `{t['Target']}` {confidence_emoji}")
    
    return "\n".join(lines)
