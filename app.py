# -*- coding: utf-8 -*-
"""mini_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n2IBjyFONCoD5MhsEQBCHDoSyauYI1p1
"""

# !pip install sentence-transformers faiss-cpu google-generativeai

import os
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import google.generativeai as genai

# Set Gemini API key (lấy miễn phí tại https://aistudio.google.com/app/apikey)
os.environ['GOOGLE_API_KEY'] = st.secrets['GOOGLE_API_KEY']
genai.configure(api_key=os.environ['GOOGLE_API_KEY'])

# Mock data từ schema (User, Project, Skill, etc.)
import pandas as pd

# Load data from CSV (giả sử file đã upload hoặc generate)
data_df = pd.read_csv('testt.csv')  # Hoặc pd.read_json nếu dùng JSON

# Tạo documents từ các fields (concat để embedding toàn bộ relation)
documents = [
    f"{row['Source']} {row['Relation']} {row['Target']}: {row['Evidence']}"
    for _, row in data_df.iterrows()
]

# Tạo metadata từ các trường liên quan
metadata = [
    {"access_level": row['Access_Level'], "verified": row['Status'] in ['Attested', 'Verified']}
    for _, row in data_df.iterrows()
]

# Embedding model nhẹ
embedder = SentenceTransformer('paraphrase-mpnet-base-v2') #SBERT
doc_embeddings = embedder.encode(documents)

# Tạo FAISS index (flat cho đơn giản)
dimension = doc_embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(doc_embeddings).astype('float32'))

# Gatekeeper filter (dựa role)
def gatekeeper_filter(user_role):
    if user_role == "Owner":
        return list(range(len(documents)))  # All
    elif user_role == "Recruiter":
        return [i for i, m in enumerate(metadata) if m["access_level"] in ["Verified", "Public"]]
    else:  # Anonymous
        return [i for i, m in enumerate(metadata) if m["access_level"] == "Public"]

# RAG function đơn giản
def simple_rag(query, user_role="Recruiter"):
    # Embed query
    query_emb = embedder.encode([query])[0]

    # Filter indices dựa role
    allowed_indices = gatekeeper_filter(user_role)
    if not allowed_indices:
        return "No access to data."

    # Retrieve top 3 từ allowed docs (manual filter)
    allowed_embs = np.array([doc_embeddings[i] for i in allowed_indices]).astype('float32')
    allowed_index = faiss.IndexFlatL2(dimension)
    allowed_index.add(allowed_embs)
    distances, indices = allowed_index.search(np.array([query_emb]).astype('float32'), k=3)

    # Get contexts
    contexts = [documents[allowed_indices[i]] for i in indices[0] if i != -1]
    context_str = "\n".join(contexts)

    # Generate với Gemini
    prompt = f"Answer based on verified context only: {context_str}\nQuestion: {query}\nAnswer:"
    model = genai.GenerativeModel('gemini-flash-latest')
    response = model.generate_content(prompt)
    return response.text

# Test
print("Owner:", simple_rag("What skills does A have?", "Owner"))
print("Recruiter:", simple_rag("What skills does A have?", "Recruiter"))
print("Anonymous:", simple_rag("What skills does A have?", "Anonymous"))

# Test với test question tiếng Việt
print("Owner:", simple_rag("Kỹ năng của A là gì?", "Owner"))
print("Recruiter:", simple_rag("Kỹ năng của A là gì?", "Recruiter"))
print("Anonymous:", simple_rag("Kỹ năng của A là gì?", "Anonymous"))

